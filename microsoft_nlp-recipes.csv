"[FEATURE] Transformer class in utils_nlp/transformers/common.py should support dataloader which doesn't have len function defined","### Description<!--- Describe your expected feature in detail -->### Expected behavior with the suggested feature<!--- For example:  --><!--- *Adding algorithm xxx will help people understand more about xxx use case scenarios. -->### Other Comments","open","512","null","[{'id':1305965080,'node_id':'MDU6TGFiZWwxMzA1OTY1MDgw','url':'https://api.github.com/repos/microsoft/nlp-recipes/labels/enhancement','name':'enhancement','color':'a2eeef','default':true,'description':'New feature or request'}]","null"
"[ASK] Missing CONTRIBUTING.md","### DescriptionThe PR form requests that users inspect the https://github.com/microsoft/nlp-recipes/CONTRIBUTING.md guide, but the file does not exist.","open","511","null","[]","null"
"Azure AutoML NLP details added to README.md","### DescriptionAdded details on how Azure Automated Machine Learning handles NLP tasks.### Related Issues<!--- If it fixes an open issue, please link to the issue here. -->### Checklist:<!--- Go over all the following points, and put an `x` in all the boxes that apply. --><!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->- [x] My code follows the code style of this project, as detailed in our [contribution guidelines](../CONTRIBUTING.md).- [ ] I have added tests.- [ ] I have updated the documentation accordingly.","open","510","null","[]","null"
"Bug fix for Issue #501","### Description<!--- Describe your changes in detail --><!--- Why is this change required? What problem does it solve? -->Bug fix for Issue #501  .Huggingface has a break change for the function `WarmupLinearSchedule`, it's been renamed to `get_linear_schedule_with_warmup` and also renamed the parameters. ### Related Issues<!--- If it fixes an open issue, please link to the issue here. -->### Checklist:<!--- Go over all the following points, and put an `x` in all the boxes that apply. --><!--- If you're unsure about any of these, don't hesitate to ask. We're here to help! -->- [ ] My code follows the code style of this project, as detailed in our [contribution guidelines](../CONTRIBUTING.md).- [ ] I have added tests.- [ ] I have updated the documentation accordingly.","open","509","null","[]","null"
"[BUG] Question Answering unit tests fail on gpu testing machine","### Description<!--- Describe your bug in detail -->tests/unit/test_models_transformers_question_answering.py succeeds on DSVM, but fails on gpu testing machine. ```tests/unit/test_common_pytorch_utils.py ......                           [ 54%]tests/unit/test_models_transformers_question_answering.py .F..           [ 90%]tests/unit/test_transformers_sequence_classification.py .                [100%]=================================== FAILURES ===================================_____________________________ test_AnswerExtractor _____________________________qa_test_data = {'test_dataset': <utils_nlp.models.transformers.datasets.QADataset object at 0x7f1447bbe828>, 'test_features_bert': <t...ject at 0x7f1446a0c780>, 'test_features_xlnet': <torch.utils.data.dataloader.DataLoader object at 0x7f14469bfd30>, ...}tmp_module = '/tmp/pytest-of-nlpadmin/pytest-1011/tmpnzdwdt1d'    @pytest.mark.gpu    def test_AnswerExtractor(qa_test_data, tmp_module):        # test bert        qa_extractor_bert = AnswerExtractor(cache_dir=tmp_module)>       qa_extractor_bert.fit(qa_test_data['train_features_bert'], cache_model=True)tests/unit/test_models_transformers_question_answering.py:197: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ utils_nlp/models/transformers/question_answering.py:551: in fit    seed=seed,utils_nlp/models/transformers/common.py:174: in fine_tune    outputs = self.model(**inputs)/data/anaconda/envs/nlp_gpu/lib/python3.6/site-packages/torch/nn/modules/module.py:547: in __call__    result = self.forward(*input, **kwargs)_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = DataParallel(  (module): BertForQuestionAnswering(    (bert): BertModel(      (embeddings): BertEmbeddings(       ...)        (activation): Tanh()      )    )    (qa_outputs): Linear(in_features=768, out_features=2, bias=True)  ))inputs = ()kwargs = {'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,         1, 1, 1, ... 0,             0,     0,     0,     0]], device='cuda:1'), 'start_positions': tensor([ 0, 17], device='cuda:1'), ...}t = Parameter containing:tensor([[-0.0005, -0.0416,  0.0131,  ..., -0.0039, -0.0335,  0.0150],        [ 0.0169, -0.0311,...18],        [ 0.0313, -0.0297, -0.0230,  ..., -0.0145, -0.0525,  0.0284]],       device='cuda:1', requires_grad=True)    def forward(self, *inputs, **kwargs):        if not self.device_ids:            return self.module(*inputs, **kwargs)            for t in chain(self.module.parameters(), self.module.buffers()):            if t.device != self.src_device_obj:                raise RuntimeError('module must have its parameters and buffers '                                   'on device {} (device_ids[0]) but found one of '>                                  'them on device: {}'.format(self.src_device_obj, t.device))E               RuntimeError: module must have its parameters and buffers on device cuda:0 (device_ids[0]) but found one of them on device: cuda:1```### How do we replicate the bug?<!--- Please be specific as possible (use a list if needed). --><!--- For example: --><!--- * Create a conda environment for gpu --><!--- * Run unit test `test_timer.py` --><!--- * ... -->### Expected behavior (i.e. solution)<!--- For example:  --><!--- * The tests for the timer should pass successfully. -->### Other Comments","open","502","hlums","[{'id':1305965078,'node_id':'MDU6TGFiZWwxMzA1OTY1MDc4','url':'https://api.github.com/repos/microsoft/nlp-recipes/labels/bug','name':'bug','color':'d73a4a','default':true,'description':'Something isn't working'}]","null"
"[BUG] Can not import WarmupLinearSchedule from transformers","### Description<!--- Describe your bug in detail -->In the latest huggingface transformers 2.2.0, WarmupLinearSchedule no longer exists. This caused error in tests: ```E           papermill.exceptions.PapermillExecutionError: E           ---------------------------------------------------------------------------E           Exception encountered at 'In [1]':E           ---------------------------------------------------------------------------E           ImportError                               Traceback (most recent call last)E           <ipython-input-1-14cd61902c6c> in <module>E                 7 from utils_nlp.common.timer import TimerE                 8 from sklearn.metrics import classification_reportE           ----> 9 from utils_nlp.models.transformers.sequence_classification import SequenceClassifierE                10 E                11 from utils_nlp.dataset import multinliE           E           /data/home/nlpadmin/myagent/_work/14/s/utils_nlp/models/transformers/sequence_classification.py in <module>E                25 )E                26 from utils_nlp.common.pytorch_utils import get_deviceE           ---> 27 from utils_nlp.models.transformers.common import MAX_SEQ_LEN, TOKENIZER_CLASS, TransformerE                28 from utils_nlp.models.transformers.datasets import SCDataSet, SPCDataSetE                29 E           E           /data/home/nlpadmin/myagent/_work/14/s/utils_nlp/models/transformers/common.py in <module>E                12 import torchE                13 from tqdm import tqdm, trangeE           ---> 14 from transformers import AdamW, WarmupLinearScheduleE                15 from transformers.modeling_bert import BERT_PRETRAINED_MODEL_ARCHIVE_MAPE                16 from transformers.modeling_distilbert import DISTILBERT_PRETRAINED_MODEL_ARCHIVE_MAPE           E           ImportError: cannot import name 'WarmupLinearSchedule'```I created #500 to temporarily pin the version of transformers to 2.1.1 which still has WarmupLinearSchedule. ### How do we replicate the bug?<!--- Please be specific as possible (use a list if needed). --><!--- For example: --><!--- * Create a conda environment for gpu --><!--- * Run unit test `test_timer.py` --><!--- * ... -->### Expected behavior (i.e. solution)<!--- For example:  --><!--- * The tests for the timer should pass successfully. -->### Other Comments","open","501","kehuangms","[{'id':1305965078,'node_id':'MDU6TGFiZWwxMzA1OTY1MDc4','url':'https://api.github.com/repos/microsoft/nlp-recipes/labels/bug','name':'bug','color':'d73a4a','default':true,'description':'Something isn't working'}]","null"
"[ASK] [tc_multi_languages_transformers.ipynb] temporary data directory and cache directory are not deleted after the notebook run","### DescriptionThe temporary directories should be deleted after the notebook run is finished.### Other Commentsconsider https://security.openstack.org/guidelines/dg_using-temporary-files-securely.html","open","495","kehuangms","[{'id':1305965078,'node_id':'MDU6TGFiZWwxMzA1OTY1MDc4','url':'https://api.github.com/repos/microsoft/nlp-recipes/labels/bug','name':'bug','color':'d73a4a','default':true,'description':'Something isn't working'}]","null"
"update text classification (BERT + AML) notebook to transformers","### Description[TC example](https://github.com/microsoft/nlp-recipes/blob/master/examples/text_classification/tc_bert_azureml.ipynb).Replace *utils_nlp.models.bert.sequence_classificationdependencies* with *utils_nlp.models.transformers.sequence_classification* dependencies","open","492","kehuangms","[{'id':1305965080,'node_id':'MDU6TGFiZWwxMzA1OTY1MDgw','url':'https://api.github.com/repos/microsoft/nlp-recipes/labels/enhancement','name':'enhancement','color':'a2eeef','default':true,'description':'New feature or request'}]","null"
"[ASK] Add Languages to all the scenarios","### DescriptionAdd languages to all scenario tables### Other Comments","open","484","null","[{'id':1498913769,'node_id':'MDU6TGFiZWwxNDk4OTEzNzY5','url':'https://api.github.com/repos/microsoft/nlp-recipes/labels/release-blocker','name':'release-blocker','color':'c2e0c6','default':false,'description':''}]","null"
"Warnings when setting up on an AzureML notebook","### DescriptionWarnings when setting up on an AzureML notebook### In which platform does it happen?Azure ML Notebooks### How do we replicate the issue?Setting up the conda environment as per the setup.md file### Expected behavior (i.e. solution)I get these warnings:ERROR: allennlp 0.9.0 has requirement pytorch-transformers==1.1.0, but you'll have pytorch-transformers 1.2.0 which is incompatible.ERROR: allennlp 0.9.0 has requirement spacy<2.2,>=2.1.0, but you'll have spacy 2.2.2 which is incompatible.ERROR: azureml-automl-core 1.0.57 has requirement azureml-dataprep<1.2.0a,>=1.1.10a, but you'll have azureml-dataprep 1.1.8 which is incompatible.ERROR: azureml-automl-core 1.0.57 has requirement numpy<=1.16.2,>=1.11.0, but you'll have numpy 1.17.2 which is incompatible.ERROR: azureml-automl-core 1.0.57 has requirement scipy<=1.1.0,>=1.0.0, but you'll have scipy 1.3.1 which is incompatible.ERROR: azureml-train-automl 1.0.57 has requirement azureml-dataprep<1.2.0a,>=1.1.10a, but you'll have azureml-dataprep 1.1.8 which is incompatible.ERROR: azureml-train-automl 1.0.57 has requirement numpy<=1.16.2,>=1.11.0, but you'll have numpy 1.17.2 which is incompatible.ERROR: azureml-train-automl 1.0.57 has requirement scipy<=1.1.0,>=1.0.0, but you'll have scipy 1.3.1 which is incompatible.ERROR: papermill 1.2.1 has requirement tqdm>=4.32.2, but you'll have tqdm 4.31.1 which is incompatible.ERROR: azureml-sdk 1.0.57 has requirement azureml-dataprep<1.2.0a,>=1.1.10a, but you'll have azureml-dataprep 1.1.8 which is incompatible.ERROR: azureml-mlflow 1.0.72.1 has requirement azureml-core==1.0.72.*, but you'll have azureml-core 1.0.57.1 which is incompatible.### Other Comments","open","465","null","[]","null"
"[Bug][Sentence Similarity]error running automl_with_pipelines_deployment_aks.ipynb ","### DescriptionThe current nlp_cpu env introduces azureml packages with version 1.0.57. While preparing for ODSC tutorial we realized that we could not use 1.0.57. We tried 1.0.48, 1.0.57 and 1.0.69 along with 1.0.53.The only identified stable version for this notebook (automl_with_pipelines_deployment_aks) is 1.0.53.","open","457","miguelgfierro","[{'id':1305965078,'node_id':'MDU6TGFiZWwxMzA1OTY1MDc4','url':'https://api.github.com/repos/microsoft/nlp-recipes/labels/bug','name':'bug','color':'d73a4a','default':true,'description':'Something isn't working'}]","null"
"[ASK] Adding custom entity labels to BERT NER ","### DescriptionIs it possible to finetune BERT NER on custom entity labels other than what is shown in https://github.com/microsoft/nlp/blob/master/examples/named_entity_recognition/ner_wikigold_bert.ipynb (Cell 4) :```Unique entity labels: ['O', 'I-LOC', 'I-MISC', 'I-PER', 'I-ORG']```### Other CommentsIt seems possible but wanted to make sure.Procedure:1. Write custom dataset file like the one for Wikigold dataset: https://github.com/microsoft/nlp/blob/master/utils_nlp/dataset/wikigold.py 2. Use this module to load entity labels, and train using the same code afterwards.","open","436","hlums","[]","null"
"[FEATURE] Docker support","### DescriptionIs Docker support on the road map? It would be useful for testing, model deploying, etc.### Expected behavior with the suggested featureWith a Docker container, I can safely deploy a model trained by using NLP repo utilities and put it into a production environment### Other Comments","open","392","null","[{'id':1305965080,'node_id':'MDU6TGFiZWwxMzA1OTY1MDgw','url':'https://api.github.com/repos/microsoft/nlp-recipes/labels/enhancement','name':'enhancement','color':'a2eeef','default':true,'description':'New feature or request'}]","null"
"[ASK] Do i need to install something else to run this notebook? https://github.com/microsoft/nlp/blob/master/examples/sentence_similarity/gensen_local.ipynb","### DescriptionWhile trying to run this notebook, https://github.com/microsoft/nlp/blob/master/examples/sentence_similarity/gensen_local.ipynb I run into this error: ---------------------------------------------------------------------------ModuleNotFoundError                       Traceback (most recent call last)<ipython-input-1-dab8bef65ca7> in <module>     10 from utils_nlp.models.pretrained_embeddings.glove import download_and_extract     11 from utils_nlp.dataset import Split---> 12 from examples.sentence_similarity.gensen_wrapper import GenSenClassifier     13      14 print('System version: {}'.format(sys.version))/data/home/jayalinuxdsvm/Desktop/nlp/examples/sentence_similarity/gensen_wrapper.py in <module>      4 import os      5 ----> 6 from examples.sentence_similarity.gensen_train import train      7 from utils_nlp.eval.classification import compute_correlation_coefficients      8 from utils_nlp.models.gensen.create_gensen_model import (/data/home/jayalinuxdsvm/Desktop/nlp/examples/sentence_similarity/gensen_train.py in <module>     22 import time     23 ---> 24 import horovod.torch as hvd     25 import mlflow     26 import numpy as npModuleNotFoundError: No module named 'horovod'### Other Comments","open","380","null","[]","null"
"[ASK] Jupyter notebook setup in Readme file","### DescriptionIn the Readme file: https://github.com/microsoft/nlp/blob/master/SETUP.md, can't the user simply type Jupyter notebook in the cmd prompt to start the notebooks in the browser? ### Other Comments","open","378","yijingchen","[]","null"
"[ASK] Should we add code in notebook "entailment_xnli_bert_azureml" to write the details of the workspace to a configuration file to the notebook library?","### Description<!--- Describe your general ask in detail -->When running the notebook, there is a step to get or create a AML workspace:```pythonws = get_or_create_workspace(    config_path=config_path,    subscription_id=subscription_id,    resource_group=resource_group,    workspace_name=workspace_name,    workspace_region=workspace_region,)```By default there is not details of workspace (no config.json). And the code complains that it cannot find the config.json file. If I already have a created AML workspace (I have all needed parameter values for this function call), the only thing I need to do is to get that config.json. ### Other CommentsHere is a simple workaround to this issue, we just need to add the following code snippet before the `get_or_create_workspace` function call, then we should be able to generate the config.json file. ```pythonfrom azureml.core import Workspacetry:    ws = Workspace(subscription_id = subscription_id,                  resource_group = resource_group,                  workspace_name = workspace_name)    # write the details of the workspace to a configuration file to the notebook library    ws.write_config()    print('Workspace configuration succeeded. Skip the workspace creation steps below')except:    print('Workspace not accessible. Change your parameters or create a new workspace below')```This only need to be done once.","open","370","null","[{'id':1510342854,'node_id':'MDU6TGFiZWwxNTEwMzQyODU0','url':'https://api.github.com/repos/microsoft/nlp-recipes/labels/bug-bash','name':'bug-bash','color':'0052cc','default':false,'description':''},{'id':1350754661,'node_id':'MDU6TGFiZWwxMzUwNzU0NjYx','url':'https://api.github.com/repos/microsoft/nlp-recipes/labels/example','name':'example','color':'e1fc9f','default':false,'description':'Example notebook'}]","null"
"[FEATURE] add clean-up instructions","### Description<!--- Describe your expected feature in detail -->https://github.com/microsoft/nlp/blob/staging/SETUP.md should mention clean-up instructions### Expected behavior with the suggested feature<!--- For example:  -->conda deactivateconda remove --name my_env_name --all### Other Comments","open","362","null","[{'id':1510342854,'node_id':'MDU6TGFiZWwxNTEwMzQyODU0','url':'https://api.github.com/repos/microsoft/nlp-recipes/labels/bug-bash','name':'bug-bash','color':'0052cc','default':false,'description':''},{'id':1305965080,'node_id':'MDU6TGFiZWwxMzA1OTY1MDgw','url':'https://api.github.com/repos/microsoft/nlp-recipes/labels/enhancement','name':'enhancement','color':'a2eeef','default':true,'description':'New feature or request'}]","null"
"[ASK] All notebooks which uses AML to create GPU compute target should provide similar code to reuse existing GPU VM","### DescriptionGPU is scare resource and we should provide users of this git repo a way to reuse their gpu machines if they already have one.### Other Comments","open","368","null","[]","null"
"[Feature] add horovod and add the tests back","### DescriptionCurrently horovod installation is not included in the environment generation scripts and documentation of horovod is not complete. So we temporarily removed all the tests related to horovod. This issue is created to track this change. Once the story of horovod installation is ready, we should add the tests back.","open","356","null","[{'id':1305965080,'node_id':'MDU6TGFiZWwxMzA1OTY1MDgw','url':'https://api.github.com/repos/microsoft/nlp-recipes/labels/enhancement','name':'enhancement','color':'a2eeef','default':true,'description':'New feature or request'}]","null"
"[ASK] Investigate distributed training performance","### Description- benchmarks- added value of distributed training/AML### Other Comments","open","343","null","[]","null"
"[ASK] Add tests with unpinned packages ","### DescriptionAdd a branch with unpinned packages in env and test pipeline to catch versioning issues### Other Comments","open","318","null","[{'id':1350756392,'node_id':'MDU6TGFiZWwxMzUwNzU2Mzky','url':'https://api.github.com/repos/microsoft/nlp-recipes/labels/engineering','name':'engineering','color':'0c0f68','default':false,'description':'Engineering tasks for repo'}]","null"
"[ASK] Merge preprocess_encoder_tokens and preprocess_classification_tokens ","### Descriptionpreprocess_encoder_tokens and preprocess_classification_tokens contain large chunk  of same code and we should rewrite this part of not repeat the same code. ### Other Comments","open","311","null","[]","null"
"[ASK] Review the ReadMe for Repo_metrics readme under Tools","### DescriptionThere is a readme for the repo metrics subfolder under tools. It needs general review to make sure it is accurate.### Other Comments**Principles of NLP Documentation**	Each landing page at the folder level should have a ReadMe which explains -		○ Summary of what this folder offers.		○ Why and how it benefits users		○ As applicable - Documentation of using it, brief description etc	**Scenarios folder:**		○ Root Scenario folder should have a summary on what value these example notebook provides.		○ Include a table with scenario name, description, algorithm, Dataset		○ Other instructions, Pre-req of running these notebooks		○ Each scenario folder should have a summary text explaining about the scenario, what utils its using. Any benchmark numbers if applicable. Explain any concept relevant to the scenario	**Example Notebooks Guiding Principles:**		○ We are providing recipes for solving NLP scenarios on Azure AI		○ We make it easier by providing Util packages		○ We provide example notebooks on how to use the utils for solving common NLP scenarios		○ Based on these principles above, all notebook examples should be using utils wherever applicable. Ex: If your example is doing classification using BERT, use the BERTSequenceClassifier instead of directly calling BertForSequenceClassification. Same with tokenization.","open","289","null","[{'id':1481750072,'node_id':'MDU6TGFiZWwxNDgxNzUwMDcy','url':'https://api.github.com/repos/microsoft/nlp-recipes/labels/documentation','name':'documentation','color':'f9d0c4','default':true,'description':'README, SETUP, etc'}]","null"
"[ASK] Rename notebook files to match naming convention","### Description<!--- Describe your general ask in detail -->Rename existing notebook files to match naming conventions:- 1 quickstart per scenario. This should be <10 minutes to train/test locally     - Naming: `'quickstart_<<Scenario>> '` for example: `quickstart_ner`- all underscores between words- all lowercase- scenario_<<free text description with dataset name>> - sen_similarity_stsbenchmark_automlScenarios:- qa- ner- text_class- sen_similarity- entail- explanation- labeling ### Other Comments","open","276","null","[]","null"
"[ASK] Doc Folder is empty. No ReadMe","### DescriptionDo we need the doc folder? If not it should be removed. Else lets add a ReadMe.### Other Comments**Principles of NLP Documentation**	Each landing page at the folder level should have a ReadMe which explains -		○ Summary of what this folder offers.		○ Why and how it benefits users		○ As applicable - Documentation of using it, brief description etc	**Scenarios folder:**		○ Root Scenario folder should have a summary on what value these example notebook provides.		○ Include a table with scenario name, description, algorithm, Dataset		○ Other instructions, Pre-req of running these notebooks		○ Each scenario folder should have a summary text explaining about the scenario, what utils its using. Any benchmark numbers if applicable. Explain any concept relevant to the scenario	**Example Notebooks Guiding Principles:**		○ We are providing recipes for solving NLP scenarios on Azure AI		○ We make it easier by providing Util packages		○ We provide example notebooks on how to use the utils for solving common NLP scenarios		○ Based on these principles above, all notebook examples should be using utils wherever applicable. Ex: If your example is doing classification using BERT, use the BERTSequenceClassifier instead of directly calling BertForSequenceClassification. Same with tokenization.","open","269","null","[{'id':1481750072,'node_id':'MDU6TGFiZWwxNDgxNzUwMDcy','url':'https://api.github.com/repos/microsoft/nlp-recipes/labels/documentation','name':'documentation','color':'f9d0c4','default':true,'description':'README, SETUP, etc'}]","null"
"[ASK] Github folder ReadMe","### DescriptionAdd a ReadMe file in the GitHub folder.Explain usage of the Templates### Other Comments**Principles of NLP Documentation**	Each landing page at the folder level should have a ReadMe which explains -		○ Summary of what this folder offers.		○ Why and how it benefits users		○ As applicable - Documentation of using it, brief description etc	**Scenarios folder:**		○ Root Scenario folder should have a summary on what value these example notebook provides.		○ Include a table with scenario name, description, algorithm, Dataset		○ Other instructions, Pre-req of running these notebooks		○ Each scenario folder should have a summary text explaining about the scenario, what utils its using. Any benchmark numbers if applicable. Explain any concept relevant to the scenario	**Example Notebooks Guiding Principles:**		○ We are providing recipes for solving NLP scenarios on Azure AI		○ We make it easier by providing Util packages		○ We provide example notebooks on how to use the utils for solving common NLP scenarios		○ Based on these principles above, all notebook examples should be using utils wherever applicable. Ex: If your example is doing classification using BERT, use the BERTSequenceClassifier instead of directly calling BertForSequenceClassification. Same with tokenization.","open","268","null","[{'id':1481750072,'node_id':'MDU6TGFiZWwxNDgxNzUwMDcy','url':'https://api.github.com/repos/microsoft/nlp-recipes/labels/documentation','name':'documentation','color':'f9d0c4','default':true,'description':'README, SETUP, etc'}]","null"
"[ASK] Make sure doc strings are in correct format for sphinx","### Description<!--- Describe your expected feature in detail -->Related to #234 Go through and check doc strings to make sure they are correct### Expected behavior with the suggested feature<!--- For example:  --><!--- *Adding algorithm xxx will help people understand more about xxx use case scenarios. -->### Other Comments","open","261","null","[{'id':1481750072,'node_id':'MDU6TGFiZWwxNDgxNzUwMDcy','url':'https://api.github.com/repos/microsoft/nlp-recipes/labels/documentation','name':'documentation','color':'f9d0c4','default':true,'description':'README, SETUP, etc'}]","null"
"[FEATURE] Splitting the notebooks for embedding","### DescriptionIn the interest of keeping the notebooks short and categorized, can we slpit them into 3 notebooks demonstrating Word2Vec, Glove and Fasttext embedding separately?### Expected behavior with the suggested featureThe Summary notes comparing the results could be included in the ReadMe of the Embedding folder.### Other Comments","open","239","yijingchen","[{'id':1305965080,'node_id':'MDU6TGFiZWwxMzA1OTY1MDgw','url':'https://api.github.com/repos/microsoft/nlp-recipes/labels/enhancement','name':'enhancement','color':'a2eeef','default':true,'description':'New feature or request'}]","null"
"[FEATURE] Automatically extract MRPC","### Description<!--- Describe your expected feature in detail -->In glue benchmark code they give some hints on how to do this: https://github.com/nyu-mll/GLUE-baselines/blob/master/download_glue_data.py### Expected behavior with the suggested feature<!--- For example:  --><!--- *Adding algorithm xxx will help people understand more about xxx use case scenarios. -->### Other Comments","open","240","null","[{'id':1305965080,'node_id':'MDU6TGFiZWwxMzA1OTY1MDgw','url':'https://api.github.com/repos/microsoft/nlp-recipes/labels/enhancement','name':'enhancement','color':'a2eeef','default':true,'description':'New feature or request'}]","null"
"[FEATURE] Setup script should include conda update ","### DescriptionConda is not up to date in DSVM. Environment create script fails without first updating conda. ### Expected behavior with the suggested featureWe should include conda update command in Setup script. ### Other Comments","open","236","null","[{'id':1305965080,'node_id':'MDU6TGFiZWwxMzA1OTY1MDgw','url':'https://api.github.com/repos/microsoft/nlp-recipes/labels/enhancement','name':'enhancement','color':'a2eeef','default':true,'description':'New feature or request'}]","null"
